{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Model with two input arrays\n",
    "# didn't work for some reason\n",
    "import keras\n",
    "import numpy as np\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Embedding, SpatialDropout1D, Concatenate\n",
    "from keras.layers import GRU, Bidirectional, GlobalAveragePooling1D, GlobalMaxPooling1D\n",
    "from keras.preprocessing import text, sequence\n",
    "from keras.callbacks import Callback\n",
    "\n",
    "\n",
    "# REMOVE ARRAY_1\n",
    "input1 = Input(shape=(29,), name='material_type')\n",
    "input2 = Input(shape=(29,), name='material_weight')\n",
    "merged = Concatenate(axis=1)([input1, input2])\n",
    "dense1 = Dense(300,input_dim=2, activation=\"relu\", use_bias=True)(merged)\n",
    "output = Dense(123, activation=\"sigmoid\")(dense1)\n",
    "    \n",
    "model =  Model(inputs=[input1, input2], outputs=output)\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['categorical_accuracy'])\n",
    "\n",
    "#tbCallBack = keras.callbacks.TensorBoard(log_dir='./Graph', histogram_freq=0, write_graph=True, write_images=True)\n",
    "train_array = [X1_TRAIN[0:10000], X2_TRAIN[0:10000]]\n",
    "test_array = [X1_TRAIN[10000:12745], X2_TRAIN[10000:12745]]\n",
    "train_Y = LABELS[0:10000]\n",
    "test_Y = LABELS[10000:12745]\n",
    "\n",
    "model.fit([X1_TRAIN,X2_TRAIN], LABELS, batch_size=64, epochs=5, validation_split=0, verbose=2) \n",
    "\n",
    "y_pred1 = model.predict([X1_TEST,X2_TEST], verbose=0)\n",
    "y_pred = np.zeros(y_pred1.shape)\n",
    "y_pred[y_pred1>0.3] = 1 \n",
    " \n",
    "#from sklearn.metrics import f1_score\n",
    "#scores = f1_score(test_Y, y_pred1 , average=\"micro\")\n",
    "#scores\n",
    "\n",
    "c = 0\n",
    "for cd in LABELS:\n",
    "     if cd[0] == 1:\n",
    "            c += 1\n",
    "\n",
    "print(len(LABELS))\n",
    "print(c)\n",
    "\n",
    "c = 0\n",
    "for cd in y_pred:\n",
    "     if cd[0] == 1:\n",
    "            c += 1\n",
    "print(len(y_pred))\n",
    "print(c)\n",
    "\n",
    "#12746\n",
    "#4901\n",
    "#8397\n",
    "#5002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "3 * 400\n",
    "\n",
    "    input1 = Input(shape=(29,) , name='material_weight')\n",
    "    dense1 = Dense(400, activation=\"relu\")(input1)\n",
    "    bn1 = BatchNormalization()(dense1)\n",
    "    \n",
    "    dense2 = Dense(400, activation=\"relu\")(bn1)##########\n",
    "    bn2 = BatchNormalization()(dense2)#\n",
    "    dense3 = Dense(400, activation=\"relu\")(bn2)#\n",
    "    bn3 = BatchNormalization()(dense3)##################\n",
    "    \n",
    "    output = Dense(123, activation=\"sigmoid\")(bn3)\n",
    "    model_CV =  Model(inputs=input1, outputs=output)\n",
    "\n",
    "    model_CV.compile(loss='binary_crossentropy',\n",
    "                    optimizer='adam',\n",
    "                    metrics=['categorical_accuracy'])\n",
    "\n",
    "    model_CV.fit(X[train], Y[train], batch_size=64, epochs=35,verbose=0 )\n",
    "    \n",
    "#   0.360 (+/- 0.008)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from skmultilearn.problem_transform import BinaryRelevance\n",
    "from skmultilearn.problem_transform import ClassifierChain\n",
    "from skmultilearn.problem_transform import LabelPowerset\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "classif = OneVsRestClassifier(model_test)\n",
    "classif.fit(X, Y)\n",
    "predicted_values = classif.predict(X_val) \n",
    "print(f1_score(Y_val, predicted_values , average=\"micro\"),'OneVsRestClassifier')  # LABELS\n",
    "\n",
    "classifierBinaryRelevance = BinaryRelevance(model_test)\n",
    "classifierBinaryRelevance.fit(X, Y)\n",
    "predicted_values = classifierBinaryRelevance.predict(X_val) \n",
    "print(f1_score(Y_val, predicted_values , average=\"micro\"),'BinaryRelevance')  # LABELS\n",
    "\n",
    "classifierChain = ClassifierChain(model_test)\n",
    "classifierChain.fit(X, Y)\n",
    "predicted_values = classifierChain.predict(X_val) \n",
    "print(f1_score(Y_val, predicted_values , average=\"micro\"),'ClassifierChain')  # LABELS\n",
    "\n",
    "classifierLabelPowerset = LabelPowerset( model_test )\n",
    "classifierLabelPowerset.fit(X, Y)\n",
    "predicted_values = classifierLabelPowerset.predict(X_val) \n",
    "print(f1_score(Y_val, predicted_values , average=\"micro\"),'LabelPowerset')  # LABELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model_3 = LabelPowerset(classifier=model_test , require_dense=[True,False])\n",
    "model_3.fit(X2_TRAIN, LABELS)\n",
    "y_pred2 = model_3.predict(X2_TEST)\n",
    "y_pred2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from skmultilearn.adapt import MLkNN\n",
    "from scipy.sparse import csr_matrix, lil_matrix\n",
    "classifier_new = MLkNN(k=3)\n",
    "\n",
    "#y_train = lil_matrix(y_train).toarray()\n",
    "#x_test = lil_matrix(x_test).toarray()# train\n",
    "classifier_new.fit(X, Y)# predict\n",
    "\n",
    "predicted_values = classifier_new.predict(X_val) \n",
    "print(f1_score(Y_val, predicted_values , average=\"micro\"))  # LABELS\n",
    "predicted_values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#model_2 = ClassifierChain( model_test, require_dense = [False, True])\n",
    "#model_2.fit( X2_TRAIN, LABELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 10-fold cross validation\n",
    "from sklearn.model_selection import KFold\n",
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, SpatialDropout1D, Concatenate,BatchNormalization\n",
    "from keras.callbacks import Callback\n",
    "import numpy\n",
    "#early_stop = keras.callbacks.EarlyStopping(monitor='acc', min_delta=0, patience=10, verbose=0, mode='auto', baseline=None)\n",
    "#reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor='acc', factor=0.2, patience=4, min_lr=0.001)\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "\n",
    "X = X2_TRAIN\n",
    "Y = LABELS\n",
    "\n",
    "kfold = KFold(n_splits=10,shuffle=True,random_state=seed)\n",
    "\n",
    "cvscores = []\n",
    "for train, test in kfold.split(X, Y):\n",
    "    input1 = Input(shape=(29,) , name='material_weight')\n",
    "    dense1 = Dense(400, activation=\"relu\")(input1)\n",
    "    bn1 = BatchNormalization()(dense1)\n",
    "    dense2 = Dense(400, activation=\"relu\")(bn1)\n",
    "    bn2 = BatchNormalization()(dense2)\n",
    "    dense3 = Dense(400, activation=\"relu\")(bn2)\n",
    "    bn3 = BatchNormalization()(dense3)\n",
    "    dense4 = Dense(400, activation=\"relu\")(bn3)\n",
    "    bn4 = BatchNormalization()(dense4)\n",
    "    output = Dense(123, activation=\"sigmoid\")(bn4)\n",
    "\n",
    "    model_CV = Model(inputs=input1, outputs=output)\n",
    "\n",
    "    model_CV.compile(loss='binary_crossentropy', \n",
    "                     optimizer='Adam',\n",
    "                     metrics=['accuracy'])\n",
    "\n",
    "    model_CV.fit(X[train], Y[train], batch_size=64, epochs=35,verbose=0 ) #, callbacks=[early_stop,reduce_lr]\n",
    "    # 38 60\n",
    "    y_pred1 = model_CV.predict(X[test], verbose=0)\n",
    "    y_pred = np.zeros(y_pred1.shape)\n",
    "    y_pred[y_pred1>0.3] = 1 \n",
    "    \n",
    "    scores = f1_score(Y[test], y_pred , average=\"micro\")\n",
    "    print(\"%s: %.3f%%\" % ('f1 micro-average: ', scores))\n",
    "    cvscores.append(scores)\n",
    "\n",
    "print(\"%.3f%% (+/- %.3f%%)\" % (np.mean(cvscores), np.std(cvscores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix\n",
    "y_pred1 = model_2.predict(X2_TRAIN, verbose=0)\n",
    "\n",
    "y_pred = np.zeros(y_pred1.shape)\n",
    "y_pred[y_pred1>0.3] = 1 \n",
    "\n",
    "print(f1_score(LABELS, y_pred, average=\"micro\"))\n",
    "#0.284 - 0.3\n",
    "\n",
    "s = y_pred1\n",
    "labels = np.zeros(s.shape)\n",
    "labels[s>0.3] = 1 \n",
    "good = 0\n",
    "bad = 0\n",
    "for d in range(len(LABELS)):\n",
    "    aaa =(labels[d] == LABELS[d])\n",
    "    if aaa.all() is True:\n",
    "        good += 1\n",
    "    else:\n",
    "        bad += 1\n",
    "        \n",
    "print(good, bad)\n",
    "#3184 9562  dense 123"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import talos\n",
    "import keras\n",
    "from keras.layers import Input, Dense, Dropout,BatchNormalization\n",
    "from keras.models import Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(X2_TRAIN, LABELS, test_size=0.2, random_state=52, shuffle = True)\n",
    "\n",
    "from keras.callbacks import EarlyStopping\n",
    "early = EarlyStopping(monitor='val_f1score', min_delta=0.0001, patience=8, mode='max')\n",
    "\n",
    "def telco_churn(x_train, y_train, x_val, y_val, params):\n",
    "    input_layer = Input(shape=(29,))\n",
    "    hidden_layer1 = Dense(400, activation='relu')(input_layer)\n",
    "    bn1 = BatchNormalization()(hidden_layer1)\n",
    "    hidden_layer2 = Dense(400, activation='relu')(bn1)\n",
    "    bn2 = BatchNormalization()(hidden_layer2)\n",
    "    hidden_layer3 = Dense(400, activation='relu')(bn2)\n",
    "    bn3 = BatchNormalization()(hidden_layer3)\n",
    "    hidden_layer4 = Dense(400, activation='relu')(bn3)\n",
    "    bn4 = BatchNormalization()(hidden_layer4)\n",
    "    output = Dense(123, activation=\"sigmoid\")(bn4)\n",
    "\n",
    "    model = Model(inputs=input_layer, outputs=output)\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=[talos.utils.metrics.f1score])\n",
    "\n",
    "    out = model.fit(x=x_train, y=y_train, validation_data=[x_val, y_val], epochs=params['epochs'],\n",
    "                    batch_size=64,verbose=0,callbacks=[early])\n",
    "   \n",
    "    return out, model\n",
    "\n",
    "#keras.layers.LeakyReLU(alpha=0.3)\n",
    "p = { 'epochs': [1,2,3,4,5,6,7,8,10,15,20,30,40,50,60], }\n",
    "#[logcosh, binary_crossentropy],\n",
    "\n",
    "scan_object = talos.Scan(x=x_train, y=y_train, x_val=x_val, y_val=y_val, params=p, \n",
    "                         model=telco_churn,experiment_name='123')\n",
    "\n",
    "d = scan_object.best_model(metric='f1score', asc=False)\n",
    "scan_object.data.sort_values(by='val_f1score', ascending=False).to_csv('HyperOpt42.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.multiclass import OneVsRestClassifier# Using pipeline for applying logistic regression and one vs rest classifier\n",
    "\n",
    "LogReg_pipeline = Pipeline([\n",
    "                ('clf', OneVsRestClassifier(LogisticRegression(solver='sag'), n_jobs=-1)),\n",
    "            ])\n",
    "\n",
    "for category in categories:\n",
    "    print('**Processing {} comments...**'.format(category))\n",
    "    \n",
    "    # Training logistic regression model on train data\n",
    "    LogReg_pipeline.fit(x_train, train[category])\n",
    "    \n",
    "    # calculating test accuracy\n",
    "    prediction = LogReg_pipeline.predict(x_test)\n",
    "    print('Test accuracy is {}'.format(accuracy_score(test[category], prediction)))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "X = np.array([[1, 2], [3, 4], [1, 2], [3, 4]])\n",
    "y = np.array([0, 0, 1, 1])\n",
    "skf = StratifiedKFold(n_splits=2)\n",
    "skf.get_n_splits(X, y)\n",
    "\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "y_pred1 = model_2.predict(X2_TEST, verbose=0)\n",
    "\n",
    "y_pred = np.zeros(y_pred1.shape)\n",
    "y_pred[y_pred1>0.3] = 1 \n",
    "\n",
    "c = 0\n",
    "for cd in LABELS:\n",
    "     if cd[0] == 1:\n",
    "            c += 1\n",
    "print(len(LABELS))\n",
    "print(c)\n",
    "\n",
    "c=0\n",
    "for cd in y_pred:\n",
    "     if cd[0] == 1:\n",
    "            c += 1\n",
    "print(len(y_pred))\n",
    "print(c)\n",
    "\n",
    "#12746\n",
    "#4901\n",
    "#8397\n",
    "#5002"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}